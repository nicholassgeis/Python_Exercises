{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learn to identify political comments versus science comments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load some text data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One source for text data is reddit.  Download some comments from\n",
    "[comments from reddit]([http://files.pushshift.io/reddit/comments/](http://files.pushshift.io/reddit/comments/)) and\n",
    "use `bz2` to decompress them.  Here, I loaded a large file called\n",
    "`RC_2010-10.bz2`.  Each line of the decompressed data is a JSON\n",
    "object, which can be decoded using `json.loads` in Python.\n",
    "\n",
    "I load over 250k comments from the &ldquo;politics&rdquo; and &ldquo;science&rdquo;\n",
    "subreddits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import bz2\n",
    "comments = []\n",
    "with bz2.open('/home/jim/downloads/RC_2010-10.bz2', 'r') as f:\n",
    "    for line in f:\n",
    "        comment = json.loads(line.strip())\n",
    "        if comment['subreddit'] in ['politics', 'science']:\n",
    "            comments.append( comment )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON is a popular format, so it behooves us to be comfortable with it.\n",
    "\n",
    "But `comment['body']` is a string of text, so we convert it to a\n",
    "vector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "vectorizer = HashingVectorizer(n_features=2**18)\n",
    "corpus = [comment['body'] for comment in comments]\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to learn `y`, the subreddit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = np.array([comment['subreddit'] == 'politics' for comment in comments])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let&rsquo;s see how well this works.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import linear_model\n",
    "model = linear_model.SGDClassifier(alpha=1e-05)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify=y)\n",
    "model.fit( X_train, y_train )\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y_test, y_pred) * 100))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the final model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we&rsquo;re happy with our model, we fit it on **all** the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.SGDClassifier(alpha=1e-05)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to save the model for later.  Let&rsquo;s dump it to disk using\n",
    "`joblib`, part of scikit-learn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "_ = joblib.dump(model, \"science-versus-politics.model\", compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reload it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"science-versus-politics.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can use it to classify text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text):\n",
    "    if model.predict(vectorizer.fit_transform([text]))[0]:\n",
    "        return 'politics'\n",
    "    else:\n",
    "        return 'science'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is probably `politics`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify('Who will win the election?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope this is `science`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify('Is there any relationship between matter and energy?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
